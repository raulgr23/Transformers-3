{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "**CCN-model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:17.532296Z",
     "iopub.status.busy": "2022-06-14T09:22:17.531868Z",
     "iopub.status.idle": "2022-06-14T09:22:20.245549Z",
     "shell.execute_reply": "2022-06-14T09:22:20.244557Z",
     "shell.execute_reply.started": "2022-06-14T09:22:17.532218Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datostransforms = Compose([Resize((224, 224)), ToTensor()])\n",
    "\n",
    "training_data = ImageFolder(root=\"../input/iais22-birds/birds/birds\", transform = transforms)\n",
    "test_data = ImageFolder(root=\"../input/iais22-birds/submission_test\", transform = transforms)\n",
    "\n",
    "train_set, test_set = random_split(training_data, (int(len(training_data) * 0.7) + 1, int(len(training_data) * 0.3)))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Training data size: {train_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:20.253809Z",
     "iopub.status.busy": "2022-06-14T09:22:20.252865Z",
     "iopub.status.idle": "2022-06-14T09:22:44.947272Z",
     "shell.execute_reply": "2022-06-14T09:22:44.946215Z",
     "shell.execute_reply.started": "2022-06-14T09:22:20.253766Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
    "\n",
    "training_data = ImageFolder(root=\"../input/iais22-birds/birds/birds\", transform = ToTensor())\n",
    "test_data = ImageFolder(root=\"../input/iais22-birds/submission_test\", transform =  ToTensor())\n",
    "\n",
    "train_set, test_set = random_split(training_data, (int(len(training_data) * 0.7) + 1, int(len(training_data) * 0.3)))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Training data size: {train_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un diccionarios que mapea los ids de las clases con sus nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:44.949205Z",
     "iopub.status.busy": "2022-06-14T09:22:44.948591Z",
     "iopub.status.idle": "2022-06-14T09:22:44.955601Z",
     "shell.execute_reply": "2022-06-14T09:22:44.954747Z",
     "shell.execute_reply.started": "2022-06-14T09:22:44.949161Z"
    }
   },
   "outputs": [],
   "source": [
    "clases_list = training_data.classes\n",
    "clases = {}\n",
    "cont = 0\n",
    "for i in clases_list:\n",
    "    clases[cont] = i\n",
    "    cont+=1\n",
    "print(clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que las imágenes están cargadas correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:44.958407Z",
     "iopub.status.busy": "2022-06-14T09:22:44.957611Z",
     "iopub.status.idle": "2022-06-14T09:22:45.618756Z",
     "shell.execute_reply": "2022-06-14T09:22:45.617947Z",
     "shell.execute_reply.started": "2022-06-14T09:22:44.958368Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = training_data.__getitem__(0)\n",
    "print(f\"Tamaño de cada imagen: {train_features.size()}\")\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(clases[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img[1][:][:], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los DataLoaders funcionan correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:45.620839Z",
     "iopub.status.busy": "2022-06-14T09:22:45.619841Z",
     "iopub.status.idle": "2022-06-14T09:22:46.122929Z",
     "shell.execute_reply": "2022-06-14T09:22:46.121132Z",
     "shell.execute_reply.started": "2022-06-14T09:22:45.620777Z"
    }
   },
   "outputs": [],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si está disponible la GPU y la seleccionamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:46.124984Z",
     "iopub.status.busy": "2022-06-14T09:22:46.12443Z",
     "iopub.status.idle": "2022-06-14T09:22:46.208053Z",
     "shell.execute_reply": "2022-06-14T09:22:46.206918Z",
     "shell.execute_reply.started": "2022-06-14T09:22:46.124939Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la arquitectura CNN basándonos en los módulos disponibles en Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:46.210573Z",
     "iopub.status.busy": "2022-06-14T09:22:46.209931Z",
     "iopub.status.idle": "2022-06-14T09:22:46.224515Z",
     "shell.execute_reply": "2022-06-14T09:22:46.223661Z",
     "shell.execute_reply.started": "2022-06-14T09:22:46.210529Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            #Input = 3 x 224 x 224, Output = 32 x 224 x 224\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1), \n",
    "            nn.ReLU(),\n",
    "            #Input = 32 x 32 x 32, Output = 32 x 112 x 112\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "  \n",
    "            #Input = 32 x 16 x 16, Output = 64 x 112 x 112\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            #Input = 64 x 16 x 16, Output = 64 x 56 x 56\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "              \n",
    "            #Input = 64 x 8 x 8, Output = 64 x 56x56\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            #Input = 64 x 8 x 8, Output = 512 x 28 x 28\n",
    "            \n",
    "            nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            #Input = 64 x 8 x 8, Output = 1024 x 2 x 2\n",
    "            nn.MaxPool2d(kernel_size=7),\n",
    "  \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024*4*4, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 400)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        image = self.network(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo, seleccionamos la GPU para el entrenamiento y la funcion de perdida y de optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:46.226541Z",
     "iopub.status.busy": "2022-06-14T09:22:46.226042Z",
     "iopub.status.idle": "2022-06-14T09:22:50.766665Z",
     "shell.execute_reply": "2022-06-14T09:22:50.765758Z",
     "shell.execute_reply.started": "2022-06-14T09:22:46.226493Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = CNN()\n",
    "model = torch.load(\"../input/modelos35/modelCNN05.pth\")\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las funciones de entrenamiento y testeo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:50.768589Z",
     "iopub.status.busy": "2022-06-14T09:22:50.76819Z",
     "iopub.status.idle": "2022-06-14T09:22:50.780393Z",
     "shell.execute_reply": "2022-06-14T09:22:50.778997Z",
     "shell.execute_reply.started": "2022-06-14T09:22:50.76855Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos y guardamos al modelo con distintos numero de epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:56.920404Z",
     "iopub.status.busy": "2022-06-14T09:22:56.920043Z",
     "iopub.status.idle": "2022-06-14T10:30:40.412995Z",
     "shell.execute_reply": "2022-06-14T10:30:40.411897Z",
     "shell.execute_reply.started": "2022-06-14T09:22:56.920373Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "torch.save(model, \"modelCNN15.pth\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
